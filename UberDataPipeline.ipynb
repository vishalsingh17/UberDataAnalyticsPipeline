{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import io\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CSV file stored in a Google Cloud Storage bucket (Replace \"uber-data-engineering-project\" with your GCS bucket name and make the data public)\n",
    "url = 'https://storage.googleapis.com/uber-data-engineering-project/uber_data.csv'\n",
    "\n",
    "# Sending a GET request to the URL to fetch the CSV file\n",
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV data from the response text and loading it into a DataFrame\n",
    "df = pd.read_csv(io.StringIO(response.text), sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'tpep_pickup_datetime' column to datetime format\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# Converting the 'tpep_dropoff_datetime' column to datetime format\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows from the DataFrame and resetting the index\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Creating a new column 'trip_id' with unique identifiers based on the DataFrame index\n",
    "df['trip_id'] = df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame 'datetime_dim' with pickup and dropoff datetime columns, and resetting the index\n",
    "datetime_dim = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting pickup datetime components\n",
    "datetime_dim['pick_hour'] = datetime_dim['tpep_pickup_datetime'].dt.hour\n",
    "datetime_dim['pick_day'] = datetime_dim['tpep_pickup_datetime'].dt.day\n",
    "datetime_dim['pick_month'] = datetime_dim['tpep_pickup_datetime'].dt.month\n",
    "datetime_dim['pick_year'] = datetime_dim['tpep_pickup_datetime'].dt.year\n",
    "datetime_dim['pick_weekday'] = datetime_dim['tpep_pickup_datetime'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting dropoff datetime components\n",
    "datetime_dim['drop_hour'] = datetime_dim['tpep_dropoff_datetime'].dt.hour\n",
    "datetime_dim['drop_day'] = datetime_dim['tpep_dropoff_datetime'].dt.day\n",
    "datetime_dim['drop_month'] = datetime_dim['tpep_dropoff_datetime'].dt.month\n",
    "datetime_dim['drop_year'] = datetime_dim['tpep_dropoff_datetime'].dt.year\n",
    "datetime_dim['drop_weekday'] = datetime_dim['tpep_dropoff_datetime'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a 'datetime_id' column with unique identifiers based on the DataFrame index\n",
    "datetime_dim['datetime_id'] = datetime_dim.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting and reordering columns for the 'datetime_dim' DataFrame\n",
    "datetime_dim = datetime_dim[['datetime_id', 'tpep_pickup_datetime', 'pick_hour', 'pick_day', 'pick_month', 'pick_year', 'pick_weekday',\n",
    "                             'tpep_dropoff_datetime', 'drop_hour', 'drop_day', 'drop_month', 'drop_year', 'drop_weekday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the 'datetime_dim' DataFrame\n",
    "datetime_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame 'passenger_count_dim' with the 'passenger_count' column and resetting the index\n",
    "passenger_count_dim = df[['passenger_count']].reset_index(drop=True)\n",
    "\n",
    "# Adding a 'passenger_count_id' column with unique identifiers based on the DataFrame index\n",
    "passenger_count_dim['passenger_count_id'] = passenger_count_dim.index\n",
    "\n",
    "# Selecting and reordering columns for the 'passenger_count_dim' DataFrame\n",
    "passenger_count_dim = passenger_count_dim[['passenger_count_id', 'passenger_count']]\n",
    "\n",
    "# Creating a new DataFrame 'trip_distance_dim' with the 'trip_distance' column and resetting the index\n",
    "trip_distance_dim = df[['trip_distance']].reset_index(drop=True)\n",
    "\n",
    "# Adding a 'trip_distance_id' column with unique identifiers based on the DataFrame index\n",
    "trip_distance_dim['trip_distance_id'] = trip_distance_dim.index\n",
    "\n",
    "# Selecting and reordering columns for the 'trip_distance_dim' DataFrame\n",
    "trip_distance_dim = trip_distance_dim[['trip_distance_id', 'trip_distance']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping RatecodeID to descriptive rate code names\n",
    "rate_code_type = {\n",
    "    1: \"Standard rate\",\n",
    "    2: \"JFK\",\n",
    "    3: \"Newark\",\n",
    "    4: \"Nassau or Westchester\",\n",
    "    5: \"Negotiated fare\",\n",
    "    6: \"Group ride\"\n",
    "}\n",
    "\n",
    "# Creating a new DataFrame 'rate_code_dim' with the 'RatecodeID' column and resetting the index\n",
    "rate_code_dim = df[['RatecodeID']].reset_index(drop=True)\n",
    "\n",
    "# Adding a 'rate_code_id' column with unique identifiers based on the DataFrame index\n",
    "rate_code_dim['rate_code_id'] = rate_code_dim.index\n",
    "\n",
    "# Mapping 'RatecodeID' to descriptive rate code names using the 'rate_code_type' dictionary\n",
    "rate_code_dim['rate_code_name'] = rate_code_dim['RatecodeID'].map(rate_code_type)\n",
    "\n",
    "# Selecting and reordering columns for the 'rate_code_dim' DataFrame\n",
    "rate_code_dim = rate_code_dim[['rate_code_id', 'RatecodeID', 'rate_code_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the 'rate_code_dim' DataFrame\n",
    "rate_code_dim.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame 'pickup_location_dim' with 'pickup_longitude' and 'pickup_latitude' columns and resetting the index\n",
    "pickup_location_dim = df[['pickup_longitude', 'pickup_latitude']].reset_index(drop=True)\n",
    "\n",
    "# Adding a 'pickup_location_id' column with unique identifiers based on the DataFrame index\n",
    "pickup_location_dim['pickup_location_id'] = pickup_location_dim.index\n",
    "\n",
    "# Selecting and reordering columns for the 'pickup_location_dim' DataFrame\n",
    "pickup_location_dim = pickup_location_dim[['pickup_location_id', 'pickup_latitude', 'pickup_longitude']]\n",
    "\n",
    "# Creating a new DataFrame 'dropoff_location_dim' with 'dropoff_longitude' and 'dropoff_latitude' columns and resetting the index\n",
    "dropoff_location_dim = df[['dropoff_longitude', 'dropoff_latitude']].reset_index(drop=True)\n",
    "\n",
    "# Adding a 'dropoff_location_id' column with unique identifiers based on the DataFrame index\n",
    "dropoff_location_dim['dropoff_location_id'] = dropoff_location_dim.index\n",
    "\n",
    "# Selecting and reordering columns for the 'dropoff_location_dim' DataFrame\n",
    "dropoff_location_dim = dropoff_location_dim[['dropoff_location_id', 'dropoff_latitude', 'dropoff_longitude']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping payment types to descriptive names\n",
    "payment_type_name = {\n",
    "    1: \"Credit card\",\n",
    "    2: \"Cash\",\n",
    "    3: \"No charge\",\n",
    "    4: \"Dispute\",\n",
    "    5: \"Unknown\",\n",
    "    6: \"Voided trip\"\n",
    "}\n",
    "\n",
    "# Creating a new DataFrame 'payment_type_dim' with the 'payment_type' column and resetting the index\n",
    "payment_type_dim = df[['payment_type']].reset_index(drop=True)\n",
    "\n",
    "# Adding a 'payment_type_id' column with unique identifiers based on the DataFrame index\n",
    "payment_type_dim['payment_type_id'] = payment_type_dim.index\n",
    "\n",
    "# Mapping 'payment_type' to descriptive payment type names using the 'payment_type_name' dictionary\n",
    "payment_type_dim['payment_type_name'] = payment_type_dim['payment_type'].map(payment_type_name)\n",
    "\n",
    "# Selecting and reordering columns for the 'payment_type_dim' DataFrame\n",
    "payment_type_dim = payment_type_dim[['payment_type_id', 'payment_type', 'payment_type_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 'fact_table' DataFrame by merging multiple dimension DataFrames on 'trip_id' and corresponding dimension IDs\n",
    "fact_table = df.merge(passenger_count_dim, left_on='trip_id', right_on='passenger_count_id') \\\n",
    "               .merge(trip_distance_dim, left_on='trip_id', right_on='trip_distance_id') \\\n",
    "               .merge(rate_code_dim, left_on='trip_id', right_on='rate_code_id') \\\n",
    "               .merge(pickup_location_dim, left_on='trip_id', right_on='pickup_location_id') \\\n",
    "               .merge(dropoff_location_dim, left_on='trip_id', right_on='dropoff_location_id') \\\n",
    "               .merge(datetime_dim, left_on='trip_id', right_on='datetime_id') \\\n",
    "               .merge(payment_type_dim, left_on='trip_id', right_on='payment_type_id') \\\n",
    "               # Selecting and reordering columns for the 'fact_table' DataFrame\n",
    "               [['trip_id', 'VendorID', 'datetime_id', 'passenger_count_id',\n",
    "                 'trip_distance_id', 'rate_code_id', 'store_and_fwd_flag', 'pickup_location_id', 'dropoff_location_id',\n",
    "                 'payment_type_id', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "                 'improvement_surcharge', 'total_amount']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the 'fact_table' DataFrame to inspect the merged results\n",
    "fact_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
